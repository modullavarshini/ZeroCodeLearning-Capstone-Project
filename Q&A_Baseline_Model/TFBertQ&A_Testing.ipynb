{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import string\n",
    "import glob\n",
    "from os import truncate\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Name</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>User_Rating</th>\n",
       "      <th>Response_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [User_Name, User_ID, Question, Answer, User_Rating, Response_Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating user_ratings_df dataframe to store the user feedback\n",
    "user_ratings_df = pd.DataFrame(columns=['User_Name','User_ID','Question','Answer','User_Rating','Response_Time'])\n",
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Loading the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings_list = ['hi','hello','hey','morning','afternoon','evening']\n",
    "account_list = ['login','account','locked','password','forgot','reset','unlock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/varshini/AMPBA/Capstone/Pilot_Models/Question_Answering/Data/General queries.txt', '/Users/varshini/AMPBA/Capstone/Pilot_Models/Question_Answering/Data/KNN & Regression specific queries.txt']\n",
      "I am a virtual assistant here to help you with MLApps platform.To unlock your account please reset your password and if the issue still persists please email our support team.To login please reset your password and if the issue still persists please email our support team.To reset your password please click on forgot password option in login page.Please click on forgot password option in login page.The left side of the screen left panel has an option of Input data Click on the Browse option and upload dataset in CSV format here.The Overview tab provides you with relevant study resources tutorials sample datasets and a short overview to start with which helps you understand and comprehend your data correctly.On the left panel there s an option called Data selection where you can select your favourable number of Y variables required to base the analysis Select and click on Apply Changes . The left panel has Advanced Options section where there is option of Select sub sample Click on the drop down option to select random number of observations for testing or the whole data itself. The left panel has Advanced Options section where there is option of Impute missing values or drop missing value rows Click on the drop down to select the option of dropping or imputing the missing values.The Data Summary tab enables you to get a comprehensive evaluation through statistical measures that help us form the basis of our analysis It will display all the descriptive analytics measures including minimum value maximum value range between data values mean median standard deviation variance etc. k nearest neighbors algorithm also known as KNN or k NN is a non parametric supervised learning classifier which uses proximity to make classifications or predictions about the grouping of an individual data point.The left panel has Advanced Options section where there is option to Set test sample percentage Use the toggle bar to set required percentage of test sample.The left panel has Advanced Options section where there is option to Select maximum nearest neighbours Use the toggle bar to set required number of nearest neighbours.The left panel has Advanced Options section where there is option to Select number of CV folds Use the toggle bar to set required number of Cross Validation CV folds. KNN results tab consists of model accuracy performance for different k values along with a graphical representation for ther same.Regression analysis is a way of mathematically sorting out which of those variables does indeed have an impact. A dependent variable is the main factor that you re trying to understand or predict. The independent variables are the factors you suspect have an impact on your dependent variable.Data visualization is the representation of data through use of common graphics such as charts plots infographics and even animations to communicate complex data relationships and data driven insights.A histogram is a graph that shows the frequency of numerical data using rectangles to give a rough sense of the density of the underlying distribution of the data and often for density estimation estimating the probability density function of the underlying variable. In a histogram the height of a rectangle the vertical axis represents the distribution frequency of a variable the amount or how often that variable appears . The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the x axis are all 1 then a histogram is identical to a relative frequency plot.A pair plot gives pairwise relationships in a dataset to understand the best set of features to explain a relationship between two variables or to form the most separated clusters. The pair plot function creates a grid of Axes such that each variable in data will be shared in the y axis across a single row and on the x axis across a single column.A Correlation Table is a two way tabulation of the relations between correlates row headings are the scores on one variable and column headings are the scores on the second variable and a cell shows how many times the score on that row was associated with the score in that column.A correlation matrix is a table showing correlation coefficients between variables where each cell in the table shows the correlation between two variables.The summary tab provides the overall analysis result under a few methods like OLS Ordinary Least Square RMSE Root Mean Square Error Variance Inflation Factor VIF etc.Ordinary Least Squares regression or OLS is a common technique for estimating coefficients of linear regression equations which describe the relationship between one or more independent quantitative variables and a dependent variable simple or multiple linear regression .Root Mean Square Error or RMSE is the standard deviation of the residuals or it tells you how concentrated the data is around the line of best fit. Residuals or errors are a measure of how far from the regression line data points are.Variance inflation factor or VIF is a measure of the amount of multicollinearity in a set of multiple regression variables and for a regression model variable is equal to the ratio of the overall model variance to the variance of a model that includes only that single independent variable. we can calculate the VIF for the variable points by performing a multiple linear regression using points as the response variable and assists and rebounds as the explanatory variables.R Squared or R² or the coefficient of determination is a statistical measure in a regression model that determines the proportion of variance in the dependent variable that can be explained by the independent variable. In other words r squared shows how well the data fit the regression model.The correlation coefficient is a specific measure that quantifies the strength of the linear relationship between two variables in a correlation analysis. A correlation analysis provides information on the strength and direction of the linear relationship between two variables while a simple linear regression analysis estimates parameters in a linear equation that can be used to predict values of one variable based on the other.The Summary OLS tab evaluates the correlation coefficients between variables and represents them through a correlation map where each cell depicts a correlation between 2 variables and the size and color of the circles in each cell depict the degree of correlation the larger the size and darker the color shade the higher is the correlation.A residual plot has the residual values on the Y axis and the independent variable on the x axis.In regression analysis prediction error quantifies how well the model predicts the response variable and in classification it quantifies how well samples are classified to the correct category.\n"
     ]
    }
   ],
   "source": [
    "#Loading the reference text\n",
    "working_dir = '/Users/varshini/AMPBA/Capstone/Pilot_Models/Question_Answering/Data'\n",
    "\n",
    "txt_files  =  glob.glob(working_dir+'//*.txt')\n",
    "print(txt_files)\n",
    "mult_text_l = []\n",
    "\n",
    "# append the different files content to a list\n",
    "for file in txt_files:\n",
    "    with open (file, 'r') as f:\n",
    "        s_text_list = f.read()\n",
    "        mult_text_l.append(s_text_list)\n",
    "\n",
    "#Appending all files into a single reference text   \n",
    "text = ' '.join(mult_text_l)\n",
    "text = text.replace('\\n', '')\n",
    "text = re.sub(\"[!\\\"#$%&'‘’()*+,\\-/:;<=>?@[\\]^_`{|}~]\", \" \", text)\n",
    "text = re.sub(' +', ' ', text)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_score(ques, answers_list) function calculates the similarity score of all question and answer pair and returns the answer with highest similarity.\n",
    "def similarity_score(ques, answers_list):\n",
    "    scores_df = pd.DataFrame(columns=['question','answer','score'])\n",
    "\n",
    "    embeddings1 = similarity_model.encode(question, convert_to_tensor=True)\n",
    "\n",
    "    for sent in answers_list:\n",
    "        embeddings2 = similarity_model.encode(sent, convert_to_tensor=True)\n",
    "        cosine_score = util.cos_sim(embeddings1, embeddings2)\n",
    "        score = '{:.4f}'.format(cosine_score[0][0])\n",
    "        scores_df.loc[len(scores_df.index)] = [question, sent, score]\n",
    "\n",
    "    scores_df = scores_df.sort_values(by=['score'], ascending=False)\n",
    "    #print(scores_df)\n",
    "    return scores_df['answer'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_ratings(question, answer, rating, response_time):\n",
    "    user_ratings_df.loc[len(user_ratings_df.index)] = ['User', len(user_ratings_df)+1, question, answer, rating, response_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question):\n",
    "    #starting time counter\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    question = re.sub(\"[!\\\"#$%&'‘’()*+,\\-/:;<=>?@[\\]^_`{|}~]\", \"\", question)\n",
    "    print(f\"Question: {question}\")\n",
    "\n",
    "    question_list = question.lower().split()\n",
    "    if any(word in question_list for word in greetings_list):\n",
    "        end_time = time.perf_counter()\n",
    "        return 'Hi! How may I help you?',end_time-start_time;\n",
    "\n",
    "    elif any(word in question_list for word in account_list):\n",
    "        end_time = time.perf_counter()\n",
    "        return 'Please reset your password and if the issue still persists, please email our support team.',end_time-start_time;\n",
    "    else:\n",
    "        #tokenize question and text as a pair\n",
    "        inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"tf\", max_length=512, truncation=True)\n",
    "        input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "        #string version of tokenized ids\n",
    "        text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        #model output using input\n",
    "        output = model(inputs)\n",
    "        #reconstructing the answer\n",
    "        answer_start = tf.argmax(\n",
    "            output.start_logits, axis=1\n",
    "        ).numpy()[0]  # Get the most likely beginning of answer with the argmax of the score\n",
    "        answer_end = (\n",
    "            tf.argmax(output.end_logits, axis=1) + 1\n",
    "        ).numpy()[0]  # Get the most likely end of answer with the argmax of the score\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "        #print(answer)\n",
    "    \n",
    "        #Returning Answer\n",
    "        if answer.startswith(\"[CLS]\") or answer.startswith(\"[SEP]\") or answer.startswith(\" \"):\n",
    "            answer = \"Unable to find the answer to your question.\"\n",
    "            #print(f\"Answer: {answer}\")\n",
    "            end_time = time.perf_counter()\n",
    "            return answer,end_time-start_time;\n",
    "        else:\n",
    "            try:\n",
    "                temp_list = []\n",
    "                answers_list = []\n",
    "                #pattern matching the sentence\n",
    "                temp_list = re.findall(r\"([^.]*?%s[^.]*\\.)\" % answer, text.lower())\n",
    "                #print(temp_list)\n",
    "                if len(temp_list)>1:\n",
    "                    for line in temp_list:\n",
    "                        answers_list.append(line)\n",
    "                    answer = similarity_score(question, answers_list)\n",
    "                    #print(f\"Answer: {answer}\")\n",
    "                    end_time = time.perf_counter()\n",
    "                    return answer,end_time-start_time;\n",
    "                else:\n",
    "                    #print(temp_list)\n",
    "                    answer = temp_list[0]\n",
    "                    #print(f\"Answer: {answer}\")\n",
    "                    end_time = time.perf_counter()\n",
    "                    return answer,end_time-start_time;\n",
    "            except IndexError:\n",
    "                #print(f\"Answer: {answer}\")\n",
    "                end_time = time.perf_counter()\n",
    "                return answer,end_time-start_time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_ratings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-226f49aa7d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_ratings_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user_ratings_df' is not defined"
     ]
    }
   ],
   "source": [
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does overview tab say\n",
      "Answer: the overview tab provides you with relevant study resources tutorials sample datasets and a short overview to start with which helps you understand and comprehend your data correctly.\n",
      "Response_Time: 7.365768436997314\n",
      "User rating is : 10\n",
      "\n",
      "Thankyou!\n"
     ]
    }
   ],
   "source": [
    "#Feedback for every question\n",
    "question = input(\"\\nHi! How may I help you? \\n\")\n",
    "while True:\n",
    "    answer, response_time = question_answer(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Response_Time: {response_time}\")\n",
    "\n",
    "    if(answer != 'Hi! How may I help you?'):\n",
    "        rating = int(input(\"\\nOn a scale of 1-10, how was your conversation experience with us? \"))\n",
    "        print(f\"User rating is : {rating}\")\n",
    "        user_ratings(question, answer, rating,response_time)\n",
    "\n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question(Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nThankyou!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
